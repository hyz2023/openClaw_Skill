#!/usr/bin/env python3
"""
ODPS AI æ£€ç´¢å·¥å…·
æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œæ™ºèƒ½æ¨èå¯æŸ¥è¯¢çš„è¡¨å’Œå­—æ®µ

åŠŸèƒ½:
1. åŠ è½½æœ¬åœ°å…ƒæ•°æ®
2. è¯­ä¹‰åŒ¹é…è¡¨å’Œå­—æ®µ
3. ç”ŸæˆæŸ¥è¯¢å»ºè®®
"""

import os
import json
from pathlib import Path
from typing import List, Dict, Tuple
import re


class ODPSSemanticSearch:
    """ODPS è¯­ä¹‰æœç´¢å¼•æ“"""
    
    def __init__(self, metadata_dir: str = 'odps_metadata'):
        self.metadata_dir = Path(metadata_dir)
        self.tables = []
        self.columns = []
        self.column_index = {}  # å­—æ®µå â†’ è¡¨åˆ—è¡¨
        self.keyword_index = {}  # å…³é”®è¯ â†’ è¡¨/å­—æ®µåˆ—è¡¨
        
        self._load_metadata()
        self._build_index()
    
    def _load_metadata(self):
        """åŠ è½½å…ƒæ•°æ®"""
        latest_json = self.metadata_dir / 'metadata_latest.json'
        latest_csv = self.metadata_dir / 'columns_latest.csv'
        
        if not latest_json.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ï¼š{latest_json}")
        
        # åŠ è½½ JSON
        with open(latest_json, 'r', encoding='utf-8') as f:
            data = json.load(f)
            self.tables = data['tables']
        
        # åŠ è½½ CSV
        import pandas as pd
        df = pd.read_csv(latest_csv)
        self.columns = df.to_dict('records')
        
        print(f"âœ… åŠ è½½ {len(self.tables)} å¼ è¡¨ï¼Œ{len(self.columns)} ä¸ªå­—æ®µ")
    
    def _build_index(self):
        """æ„å»ºç´¢å¼•"""
        # å­—æ®µåç´¢å¼•
        for col in self.columns:
            col_name = col['column_name'].lower()
            if col_name not in self.column_index:
                self.column_index[col_name] = []
            self.column_index[col_name].append(col)
        
        # å…³é”®è¯ç´¢å¼• (ä»æ³¨é‡Šä¸­æå–)
        for table in self.tables:
            table_name = table['table_name']
            
            # è¡¨æ³¨é‡Šåˆ†è¯
            if table.get('comment'):
                keywords = self._extract_keywords(table['comment'])
                for kw in keywords:
                    if kw not in self.keyword_index:
                        self.keyword_index[kw] = []
                    self.keyword_index[kw].append({
                        'type': 'table',
                        'name': table_name,
                        'match': 'comment'
                    })
            
            # å­—æ®µæ³¨é‡Šåˆ†è¯
            for col in table['columns']:
                if col.get('comment'):
                    keywords = self._extract_keywords(col['comment'])
                    for kw in keywords:
                        if kw not in self.keyword_index:
                            self.keyword_index[kw] = []
                        self.keyword_index[kw].append({
                            'type': 'column',
                            'table': table_name,
                            'column': col['name'],
                            'match': 'comment'
                        })
    
    def _extract_keywords(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯"""
        if not text:
            return []
        
        # ä¸­æ–‡åˆ†è¯ (ç®€å•æŒ‰å­—ç¬¦)
        keywords = []
        
        # è‹±æ–‡å•è¯
        english_words = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', text.lower())
        keywords.extend(english_words)
        
        # ä¸­æ–‡å…³é”®è¯ (2-4 å­—)
        chinese_chars = re.findall(r'[\u4e00-\u9fa5]{2,4}', text)
        keywords.extend(chinese_chars)
        
        # å¸¸è§ä¸šåŠ¡è¯æ±‡
        business_terms = {
            'ç”¨æˆ·': ['user', 'login', 'customer'],
            'æŠ•æ³¨': ['bet', 'wager', 'order'],
            'é‡‘é¢': ['amount', 'money', 'sum'],
            'æ—¶é—´': ['time', 'date', 'bill'],
            'æ¸¸æˆ': ['game', 'play'],
            'è®¢å•': ['order', 'bill'],
            'å¹³å°': ['platform', 'channel'],
            'è®¾å¤‡': ['device', 'mobile', 'app'],
            'æ”¶å…¥': ['revenue', 'income', 'ggr'],
            'è¾“èµ¢': ['win', 'loss', 'winloss']
        }
        
        for term, synonyms in business_terms.items():
            if term in text:
                keywords.extend(synonyms)
        
        return list(set(keywords))
    
    def search(self, query: str, top_k: int = 10) -> Dict:
        """
        æœç´¢åŒ¹é…çš„è¡¨å’Œå­—æ®µ
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢ (è‡ªç„¶è¯­è¨€)
            top_k: è¿”å›ç»“æœæ•°é‡
        
        Returns:
            åŒ¹é…çš„è¡¨å’Œå­—æ®µåˆ—è¡¨
        """
        print(f"\nğŸ” åˆ†ææŸ¥è¯¢ï¼š{query}")
        
        # 1. æå–æŸ¥è¯¢å…³é”®è¯
        query_keywords = self._extract_keywords(query)
        print(f"ğŸ“ æå–å…³é”®è¯ï¼š{', '.join(query_keywords[:10])}")
        
        # 2. å­—æ®µååŒ¹é…
        field_matches = []
        for kw in query_keywords:
            if kw in self.column_index:
                for col in self.column_index[kw]:
                    field_matches.append({
                        'table': col['table_name'],
                        'column': col['column_name'],
                        'type': col['column_type'],
                        'match_type': 'field_name',
                        'score': 1.0
                    })
        
        # 3. æ³¨é‡Šå…³é”®è¯åŒ¹é…
        comment_matches = []
        for kw in query_keywords:
            if kw in self.keyword_index:
                for item in self.keyword_index[kw]:
                    if item['type'] == 'table':
                        comment_matches.append({
                            'table': item['name'],
                            'column': '*',
                            'type': 'table',
                            'match_type': 'table_comment',
                            'score': 0.8
                        })
                    else:
                        comment_matches.append({
                            'table': item['table'],
                            'column': item['column'],
                            'type': 'column',
                            'match_type': 'column_comment',
                            'score': 0.9
                        })
        
        # 4. åˆå¹¶ç»“æœå¹¶å»é‡
        all_matches = field_matches + comment_matches
        
        # æŒ‰è¡¨åˆ†ç»„
        table_scores = {}
        for match in all_matches:
            table = match['table']
            if table not in table_scores:
                table_scores[table] = {
                    'table': table,
                    'score': 0,
                    'columns': [],
                    'match_types': set()
                }
            
            table_scores[table]['score'] += match['score']
            table_scores[table]['match_types'].add(match['match_type'])
            
            if match['column'] != '*' and match['column'] not in [c['name'] for c in table_scores[table]['columns']]:
                table_scores[table]['columns'].append({
                    'name': match['column'],
                    'type': match.get('type', 'unknown'),
                    'match_type': match['match_type']
                })
        
        # 5. æ’åº
        results = sorted(
            table_scores.values(),
            key=lambda x: x['score'],
            reverse=True
        )[:top_k]
        
        # è½¬æ¢é›†åˆä¸ºåˆ—è¡¨
        for r in results:
            r['match_types'] = list(r['match_types'])
        
        return {
            'query': query,
            'keywords': query_keywords[:10],
            'matched_tables': results,
            'total_matches': len(results)
        }
    
    def generate_query_suggestion(self, search_result: Dict, intent: str = 'query') -> str:
        """
        ç”ŸæˆæŸ¥è¯¢å»ºè®®
        
        Args:
            search_result: æœç´¢ç»“æœ
            intent: æŸ¥è¯¢æ„å›¾ (query/count/sum/detail)
        """
        if not search_result['matched_tables']:
            return "âŒ æœªæ‰¾åˆ°åŒ¹é…çš„è¡¨å’Œå­—æ®µ"
        
        tables = search_result['matched_tables']
        primary_table = tables[0]
        
        # æ ¹æ®æ„å›¾ç”Ÿæˆ SQL
        if intent == 'count':
            sql = f"""
-- æŸ¥è¯¢ {primary_table['table']} çš„è®°å½•æ•°
SELECT 
    pt,
    COUNT(*) AS cnt
FROM {primary_table['table']}
WHERE pt >= DATE_SUB(GETDATE(), 7)
GROUP BY pt
ORDER BY pt DESC;
"""
        elif intent == 'sum':
            # æ‰¾æ•°å€¼å­—æ®µ
            amount_cols = [c for c in primary_table['columns'] 
                          if 'amount' in c['name'].lower() or 'sum' in c['name'].lower()]
            if amount_cols:
                col = amount_cols[0]['name']
                sql = f"""
-- ç»Ÿè®¡ {primary_table['table']} çš„ {col} æ€»å’Œ
SELECT 
    pt,
    SUM(CAST({col} AS DOUBLE)) AS total_{col.lower()}
FROM {primary_table['table']}
WHERE pt >= DATE_SUB(GETDATE(), 7)
GROUP BY pt
ORDER BY pt DESC;
"""
            else:
                sql = f"-- è¡¨ {primary_table['table']} æœªæ‰¾åˆ°é‡‘é¢å­—æ®µ"
        
        elif intent == 'detail':
            cols = ', '.join([c['name'] for c in primary_table['columns'][:10]])
            sql = f"""
-- æŸ¥è¯¢ {primary_table['table']} çš„è¯¦ç»†æ•°æ®
SELECT 
    {cols}
FROM {primary_table['table']}
WHERE pt = GETDATE()
LIMIT 100;
"""
        
        else:  # query
            cols = ', '.join([c['name'] for c in primary_table['columns'][:15]])
            sql = f"""
-- æŸ¥è¯¢ {primary_table['table']}
SELECT 
    {cols}
FROM {primary_table['table']}
WHERE pt >= DATE_SUB(GETDATE(), 7)
LIMIT 1000;
"""
        
        return sql
    
    def interactive_search(self):
        """äº¤äº’å¼æœç´¢"""
        print("\n" + "="*60)
        print("ğŸ¤– ODPS AI æ£€ç´¢åŠ©æ‰‹")
        print("="*60)
        print("è¾“å…¥æŸ¥è¯¢æè¿°ï¼Œæˆ‘ä¼šæ¨èç›¸å…³çš„è¡¨å’Œå­—æ®µ")
        print("è¾“å…¥ 'quit' é€€å‡º")
        print("="*60)
        
        while True:
            query = input("\nğŸ“ è¯·è¾“å…¥æŸ¥è¯¢éœ€æ±‚ï¼š").strip()
            
            if query.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ å†è§!")
                break
            
            if not query:
                continue
            
            # æœç´¢
            result = self.search(query)
            
            # æ˜¾ç¤ºç»“æœ
            self._print_results(result)
            
            # ç”Ÿæˆ SQL å»ºè®®
            print("\nğŸ’¡ SQL æŸ¥è¯¢å»ºè®®:")
            print("-" * 60)
            sql = self.generate_query_suggestion(result)
            print(sql)


def _print_results(self, result: Dict):
    """æ‰“å°æœç´¢ç»“æœ"""
    print("\n" + "="*60)
    print(f"ğŸ“Š æ‰¾åˆ° {result['total_matches']} ä¸ªåŒ¹é…çš„è¡¨")
    print("="*60)
    
    for i, table in enumerate(result['matched_tables'], 1):
        print(f"\n{i}. ğŸ“ {table['table']} (åŒ¹é…åº¦ï¼š{table['score']:.2f})")
        print(f"   åŒ¹é…ç±»å‹ï¼š{', '.join(table['match_types'])}")
        
        if table['columns']:
            print(f"   æ¨èå­—æ®µ:")
            for col in table['columns'][:5]:
                print(f"     - {col['name']} ({col['type']}) [{col['match_type']}]")


# ç»‘å®šæ–¹æ³•
ODPSSemanticSearch._print_results = _print_results


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ODPS AI æ£€ç´¢å·¥å…·')
    parser.add_argument('--query', '-q', type=str, help='æŸ¥è¯¢è¯­å¥')
    parser.add_argument('--metadata-dir', default='odps_metadata', help='å…ƒæ•°æ®ç›®å½•')
    parser.add_argument('--interactive', '-i', action='store_true', help='äº¤äº’æ¨¡å¼')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æœç´¢å¼•æ“
    try:
        searcher = ODPSSemanticSearch(args.metadata_dir)
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        print("\nè¯·å…ˆè¿è¡Œå…ƒæ•°æ®é‡‡é›†:")
        print("  python odps_metadata_crawler.py")
        return
    
    if args.interactive or not args.query:
        # äº¤äº’æ¨¡å¼
        searcher.interactive_search()
    else:
        # å•æ¬¡æŸ¥è¯¢
        result = searcher.search(args.query)
        searcher._print_results(result)
        
        print("\nğŸ’¡ SQL æŸ¥è¯¢å»ºè®®:")
        print("-" * 60)
        sql = searcher.generate_query_suggestion(result)
        print(sql)


if __name__ == '__main__':
    main()
