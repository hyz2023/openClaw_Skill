#!/usr/bin/env python3
"""
ODPS æŠ•æ³¨æ•°æ®åˆ†æè„šæœ¬
ä» ODPS t_order_all è¡¨æå–æœ€è¿‘ä¸€ä¸ªæœˆæ•°æ®ï¼Œè¿›è¡Œç»Ÿè®¡åˆ†æ

ä½¿ç”¨å‰é…ç½®ç¯å¢ƒå˜é‡:
export ALIBABA_ACCESSKEY_ID="your_access_key_id"
export ALIBABA_ACCESSKEY_SECRET="your_access_key_secret"
export ALIBABA_ODPS_ENDPOINT="http://service.odps.aliyun.com/api"
export ALIBABA_ODPS_PROJECT="your_project_name"
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import subprocess
import sys


def check_odps_config():
    """æ£€æŸ¥ ODPS é…ç½®"""
    required_vars = [
        'ALIBABA_ACCESSKEY_ID',
        'ALIBABA_ACCESSKEY_SECRET',
        'ALIBABA_ODPS_PROJECT'
    ]
    
    missing = [var for var in required_vars if not os.getenv(var)]
    
    if missing:
        print("âŒ ç¼ºå°‘ ODPS é…ç½®ç¯å¢ƒå˜é‡:")
        for var in missing:
            print(f"   - {var}")
        print("\nè¯·è®¾ç½®ç¯å¢ƒå˜é‡åé‡è¯•:")
        print("  export ALIBABA_ACCESSKEY_ID='your_key_id'")
        print("  export ALIBABA_ACCESSKEY_SECRET='your_key_secret'")
        print("  export ALIBABA_ODPS_PROJECT='your_project'")
        print("  export ALIBABA_ODPS_ENDPOINT='http://service.odps.aliyun.com/api' (å¯é€‰)")
        return False
    
    return True


def query_odps_data(project: str, days: int = 30) -> pd.DataFrame:
    """
    ä» ODPS æŸ¥è¯¢æœ€è¿‘ N å¤©çš„æŠ•æ³¨æ•°æ®
    
    Args:
        project: ODPS é¡¹ç›®åç§°
        days: æŸ¥è¯¢å¤©æ•° (é»˜è®¤ 30 å¤©)
    
    Returns:
        DataFrame with columns: ordersourcetype, user_count, bet_count, bet_amount
    """
    try:
        from odps import ODPS
    except ImportError:
        print("è¯·å®‰è£… ODPS åº“ï¼špip install odps")
        return None
    
    # åˆå§‹åŒ– ODPS å®¢æˆ·ç«¯
    access_id = os.getenv('ALIBABA_ACCESSKEY_ID')
    access_key = os.getenv('ALIBABA_ACCESSKEY_SECRET')
    endpoint = os.getenv('ALIBABA_ODPS_ENDPOINT', 'http://service.odps.aliyun.com/api')
    
    print(f"è¿æ¥ ODPS é¡¹ç›®ï¼š{project}")
    
    o = ODPS(
        access_id=access_id,
        secret_access_key=access_key,
        project=project,
        endpoint=endpoint
    )
    
    # è®¡ç®—æ—¥æœŸèŒƒå›´
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=days)).strftime('%Y%m%d')
    
    # SQL æŸ¥è¯¢ï¼šç»Ÿè®¡ä¸åŒå“ç±»çš„ç”¨æˆ·æ•°ã€æŠ•æ³¨æ¬¡æ•°ã€æŠ•æ³¨é‡‘é¢
    sql = f"""
    SELECT 
        ordersourcetype AS source_type,
        COUNT(DISTINCT login_name) AS user_count,
        COUNT(*) AS bet_count,
        SUM(bet_amount) AS total_amount,
        AVG(bet_amount) AS avg_amount,
        MIN(bet_amount) AS min_amount,
        MAX(bet_amount) AS max_amount
    FROM 
        t_order_all
    WHERE 
        dt >= '{start_date}'
        AND dt <= '{end_date}'
        AND ordersourcetype IS NOT NULL
    GROUP BY 
        ordersourcetype
    ORDER BY 
        user_count DESC
    """
    
    print(f"æ‰§è¡Œ SQL æŸ¥è¯¢ (æœ€è¿‘ {days} å¤©)...")
    print(f"SQL: {sql[:200]}...")
    
    # æ‰§è¡ŒæŸ¥è¯¢
    with o.execute_sql(sql).open_reader() as reader:
        df = reader.to_pandas()
    
    print(f"æŸ¥è¯¢å®Œæˆï¼Œè·å– {len(df)} ä¸ªå“ç±»æ•°æ®")
    
    return df


def generate_sample_data() -> pd.DataFrame:
    """ç”Ÿæˆç¤ºä¾‹æ•°æ® (ç”¨äºæµ‹è¯•)"""
    np.random.seed(42)
    
    source_types = [
        'APP_IOS', 'APP_ANDROID', 'WAP', 'PC', 'H5', 
        'API', 'WECHAT', 'ALIPAY'
    ]
    
    n_sources = len(source_types)
    
    data = {
        'source_type': source_types,
        'user_count': np.random.randint(1000, 50000, n_sources),
        'bet_count': np.random.randint(5000, 200000, n_sources),
        'total_amount': np.random.uniform(100000, 5000000, n_sources),
        'avg_amount': np.random.uniform(50, 500, n_sources),
        'min_amount': np.random.uniform(10, 50, n_sources),
        'max_amount': np.random.uniform(10000, 100000, n_sources)
    }
    
    df = pd.DataFrame(data)
    df['total_amount'] = df['total_amount'].round(2)
    df['avg_amount'] = df['avg_amount'].round(2)
    
    return df


def analyze_betting_data(df: pd.DataFrame, output_dir: str = None) -> dict:
    """
    åˆ†ææŠ•æ³¨æ•°æ®
    
    Args:
        df: æ•°æ® DataFrame (åŒ…å« source_type, user_count, bet_count, total_amount ç­‰åˆ—)
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        åˆ†æç»“æœå­—å…¸
    """
    print("\n" + "="*60)
    print("ğŸ“Š åšå½©æ•°æ®åˆ†ææŠ¥å‘Š")
    print("="*60)
    
    results = {}
    
    # 1. åŸºæœ¬ç»Ÿè®¡
    print("\n## 1. åŸºæœ¬ç»Ÿè®¡")
    print("-" * 40)
    
    total_users = df['user_count'].sum()
    total_bets = df['bet_count'].sum()
    total_amount = df['total_amount'].sum()
    
    print(f"æ€»æŠ•æ³¨ç”¨æˆ·æ•°ï¼š{total_users:,}")
    print(f"æ€»æŠ•æ³¨æ¬¡æ•°ï¼š{total_bets:,}")
    print(f"æ€»æŠ•æ³¨é‡‘é¢ï¼š{total_amount:,.2f}")
    print(f"å“ç±»æ•°é‡ï¼š{len(df)}")
    print(f"å¹³å‡å•å“ç±»ç”¨æˆ·æ•°ï¼š{df['user_count'].mean():,.0f}")
    print(f"å¹³å‡å•å“ç±»æŠ•æ³¨é¢ï¼š{df['total_amount'].mean():,.2f}")
    
    results['basic_stats'] = {
        'total_users': total_users,
        'total_bets': total_bets,
        'total_amount': total_amount,
        'source_count': len(df)
    }
    
    # 2. å“ç±»æ’ååˆ†æ
    print("\n## 2. å“ç±»æ’ååˆ†æ (æŒ‰ç”¨æˆ·æ•°)")
    print("-" * 40)
    
    df_sorted = df.sort_values('user_count', ascending=False)
    
    print("\n| æ’å | å“ç±» | ç”¨æˆ·æ•° | å æ¯” | æŠ•æ³¨æ¬¡æ•° | æŠ•æ³¨é¢ |")
    print("|------|------|--------|------|----------|--------|")
    
    for i, (_, row) in enumerate(df_sorted.iterrows(), 1):
        user_pct = row['user_count'] / total_users * 100
        print(f"| {i} | {row['source_type']} | {row['user_count']:,} | {user_pct:.1f}% | {row['bet_count']:,} | {row['total_amount']:,.0f} |")
    
    results['ranking'] = df_sorted.to_dict('records')
    
    # 3. é›†ä¸­åº¦åˆ†æ
    print("\n## 3. é›†ä¸­åº¦åˆ†æ")
    print("-" * 40)
    
    # CR3/CR5 é›†ä¸­åº¦
    top3_users = df_sorted.head(3)['user_count'].sum()
    top5_users = df_sorted.head(5)['user_count'].sum()
    
    cr3 = top3_users / total_users * 100
    cr5 = top5_users / total_users * 100
    
    print(f"CR3 (å‰ 3 å¤§å“ç±»é›†ä¸­åº¦): {cr3:.1f}%")
    print(f"CR5 (å‰ 5 å¤§å“ç±»é›†ä¸­åº¦): {cr5:.1f}%")
    
    # èµ«èŠ¬è¾¾å°”æŒ‡æ•° (HHI)
    hhi = sum((row['user_count'] / total_users) ** 2 for _, row in df.iterrows()) * 10000
    print(f"èµ«èŠ¬è¾¾å°”æŒ‡æ•° (HHI): {hhi:.0f}")
    
    if hhi < 1500:
        hhi_interpretation = "ç«äº‰å‹å¸‚åœº (åˆ†æ•£)"
    elif hhi < 2500:
        hhi_interpretation = "é€‚åº¦é›†ä¸­"
    else:
        hhi_interpretation = "é«˜åº¦é›†ä¸­"
    
    print(f"å¸‚åœºç»“æ„ï¼š{hhi_interpretation}")
    
    results['concentration'] = {
        'cr3': cr3,
        'cr5': cr5,
        'hhi': hhi,
        'interpretation': hhi_interpretation
    }
    
    # 4. è¶‹åŠ¿åˆ†æ (æ¨¡æ‹Ÿæ—¶é—´åºåˆ—)
    print("\n## 4. å“ç±»å¯¹æ¯”åˆ†æ")
    print("-" * 40)
    
    # ç”¨æˆ·ä»·å€¼åˆ†æ (ARPU)
    df['arpu'] = df['total_amount'] / df['user_count']
    
    print("\nç”¨æˆ·å¹³å‡ä»·å€¼ (ARPU) æ’å:")
    arpu_ranking = df.sort_values('arpu', ascending=False)
    
    for i, (_, row) in enumerate(arpu_ranking.head(5).iterrows(), 1):
        print(f"  {i}. {row['source_type']}: Â¥{row['arpu']:.2f}/ç”¨æˆ·")
    
    # æŠ•æ³¨é¢‘ç‡åˆ†æ
    df['bet_freq'] = df['bet_count'] / df['user_count']
    
    print("\nç”¨æˆ·æŠ•æ³¨é¢‘ç‡æ’å:")
    freq_ranking = df.sort_values('bet_freq', ascending=False)
    
    for i, (_, row) in enumerate(freq_ranking.head(5).iterrows(), 1):
        print(f"  {i}. {row['source_type']}: {row['bet_freq']:.1f} æ¬¡/ç”¨æˆ·")
    
    results['arpu_analysis'] = {
        'top_arpu': arpu_ranking.head(5)[['source_type', 'arpu']].to_dict('records'),
        'top_frequency': freq_ranking.head(5)[['source_type', 'bet_freq']].to_dict('records')
    }
    
    # 5. å¼‚å¸¸æ£€æµ‹
    print("\n## 5. å¼‚å¸¸æ£€æµ‹")
    print("-" * 40)
    
    # Z-Score æ£€æµ‹å¼‚å¸¸å€¼
    from scipy import stats
    
    z_scores_users = np.abs(stats.zscore(df['user_count']))
    z_scores_amount = np.abs(stats.zscore(df['total_amount']))
    
    anomalies = []
    
    for i, (_, row) in enumerate(df.iterrows()):
        if z_scores_users[i] > 2 or z_scores_amount[i] > 2:
            anomalies.append({
                'source_type': row['source_type'],
                'user_zscore': z_scores_users[i],
                'amount_zscore': z_scores_amount[i]
            })
    
    if anomalies:
        print(f"å‘ç° {len(anomalies)} ä¸ªå¼‚å¸¸å“ç±»:")
        for a in anomalies:
            print(f"  âš ï¸  {a['source_type']}: ç”¨æˆ·æ•° Z={a['user_zscore']:.2f}, é‡‘é¢ Z={a['amount_zscore']:.2f}")
    else:
        print("âœ… æœªå‘ç°æ˜¾è‘—å¼‚å¸¸å“ç±»")
    
    results['anomalies'] = anomalies
    
    # 6. å¯è§†åŒ–æ•°æ®å‡†å¤‡
    print("\n## 6. å¯è§†åŒ–å»ºè®®")
    print("-" * 40)
    print("å»ºè®®ç”Ÿæˆä»¥ä¸‹å›¾è¡¨:")
    print("  1. æŸ±çŠ¶å›¾ï¼šå„å“ç±»ç”¨æˆ·æ•°å¯¹æ¯”")
    print("  2. é¥¼å›¾ï¼šç”¨æˆ·æ•°å æ¯”åˆ†å¸ƒ")
    print("  3. æ•£ç‚¹å›¾ï¼šARPU vs æŠ•æ³¨é¢‘ç‡")
    print("  4. çƒ­åŠ›å›¾ï¼šå“ç±» Ã— æŒ‡æ ‡ç›¸å…³æ€§")
    
    # ä¿å­˜åˆ†æç»“æœ
    if output_dir:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†æ•°æ®
        df.to_csv(output_path / 'source_type_analysis.csv', index=False)
        print(f"\nğŸ“ è¯¦ç»†æ•°æ®å·²ä¿å­˜ï¼š{output_path / 'source_type_analysis.csv'}")
        
        # ä¿å­˜åˆ†ææŠ¥å‘Š
        report_path = output_path / 'analysis_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ODPS æŠ•æ³¨æ•°æ®åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"åˆ†ææ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"## æ€»è§ˆ\n")
            f.write(f"- æ€»ç”¨æˆ·æ•°ï¼š{total_users:,}\n")
            f.write(f"- æ€»æŠ•æ³¨æ¬¡æ•°ï¼š{total_bets:,}\n")
            f.write(f"- æ€»æŠ•æ³¨é‡‘é¢ï¼š{total_amount:,.2f}\n")
            f.write(f"- å“ç±»æ•°é‡ï¼š{len(df)}\n\n")
            f.write(f"## é›†ä¸­åº¦\n")
            f.write(f"- CR3: {cr3:.1f}%\n")
            f.write(f"- CR5: {cr5:.1f}%\n")
            f.write(f"- HHI: {hhi:.0f} ({hhi_interpretation})\n")
        
        print(f"ğŸ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜ï¼š{report_path}")
    
    return results


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ODPS æŠ•æ³¨æ•°æ®åˆ†æ')
    parser.add_argument('--project', default=None, help='ODPS é¡¹ç›®åç§°')
    parser.add_argument('--days', type=int, default=30, help='æŸ¥è¯¢å¤©æ•° (é»˜è®¤ 30)')
    parser.add_argument('--output', default='reports/betting_analysis', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--sample', action='store_true', help='ä½¿ç”¨ç¤ºä¾‹æ•°æ® (æµ‹è¯•ç”¨)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æˆ–ä½¿ç”¨ç¤ºä¾‹æ•°æ®
    if args.sample:
        print("ä½¿ç”¨ç¤ºä¾‹æ•°æ®è¿›è¡Œåˆ†æ...\n")
        df = generate_sample_data()
    else:
        if not check_odps_config():
            print("\nåˆ‡æ¢åˆ°ç¤ºä¾‹æ•°æ®æ¨¡å¼...")
            df = generate_sample_data()
        else:
            project = args.project or os.getenv('ALIBABA_ODPS_PROJECT')
            if not project:
                print("è¯·æŒ‡å®š ODPS é¡¹ç›®åç§° (--project) æˆ–è®¾ç½® ALIBABA_ODPS_PROJECT ç¯å¢ƒå˜é‡")
                sys.exit(1)
            
            df = query_odps_data(project, args.days)
            
            if df is None or len(df) == 0:
                print("æŸ¥è¯¢å¤±è´¥æˆ–æ— æ•°æ®ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®...")
                df = generate_sample_data()
    
    # æ‰§è¡Œåˆ†æ
    results = analyze_betting_data(df, args.output)
    
    print("\n" + "="*60)
    print("âœ… åˆ†æå®Œæˆ!")
    print("="*60)


if __name__ == '__main__':
    main()
